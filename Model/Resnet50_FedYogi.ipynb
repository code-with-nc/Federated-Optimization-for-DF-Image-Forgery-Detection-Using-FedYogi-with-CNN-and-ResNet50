{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "1. Imports and Setup",
   "id": "462a05fb100c4191"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-04T12:16:01.298128Z",
     "start_time": "2025-11-04T11:57:28.199249Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# -------------------------------------------------------------\n",
    "# 1. Imports and Setup\n",
    "# -------------------------------------------------------------\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision import models, datasets\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import os, random, copy\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# 2. ResNet50 Model Definition\n",
    "# -------------------------------------------------------------\n",
    "class ResNetModel(nn.Module):\n",
    "    def __init__(self, num_classes=2, pretrained=True):\n",
    "        super(ResNetModel, self).__init__()\n",
    "        if pretrained:\n",
    "            weights = models.ResNet50_Weights.DEFAULT\n",
    "        else:\n",
    "            weights = None\n",
    "\n",
    "        self.resnet = models.resnet50(weights=weights)\n",
    "\n",
    "        # Optional: freeze low-level feature extractors\n",
    "        for param in self.resnet.layer1.parameters():\n",
    "            param.requires_grad = False\n",
    "        for param in self.resnet.layer2.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "        in_features = self.resnet.fc.in_features\n",
    "        self.resnet.fc = nn.Linear(in_features, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.resnet(x)\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# 3. Load and Split Dataset\n",
    "# -------------------------------------------------------------\n",
    "source_au = r\"C:\\Users\\Admin\\OneDrive\\Desktop\\ResearchTrack\\CASIA_FL_Project\\CASIA 1.0 dataset\\CASIA 1.0 dataset\\Au\\Au\"\n",
    "source_tp = r\"C:\\Users\\Admin\\OneDrive\\Desktop\\ResearchTrack\\CASIA_FL_Project\\CASIA 1.0 dataset\\CASIA 1.0 dataset\\Modified Tp\\Tp\"\n",
    "\n",
    "DATA_ROOT = r\"C:\\Users\\Admin\\OneDrive\\Desktop\\ResearchTrack\\CASIA_FL_Project\\data\"\n",
    "os.makedirs(os.path.join(DATA_ROOT, \"Authentic\"), exist_ok=True)\n",
    "os.makedirs(os.path.join(DATA_ROOT, \"Tampered\"), exist_ok=True)\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  # ResNet input size\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "full_dataset = datasets.ImageFolder(DATA_ROOT, transform=transform)\n",
    "\n",
    "train_size = int(0.75 * len(full_dataset))\n",
    "test_size = int(0.20 * len(full_dataset))\n",
    "eval_size = len(full_dataset) - train_size - test_size\n",
    "train_set, test_set, eval_set = random_split(full_dataset, [train_size, test_size, eval_size])\n",
    "\n",
    "def split_data(dataset, num_clients=10):\n",
    "    data_per_client = len(dataset) // num_clients\n",
    "    client_data = []\n",
    "    for i in range(num_clients):\n",
    "        indices = list(range(i * data_per_client, (i + 1) * data_per_client))\n",
    "        client_data.append(torch.utils.data.Subset(dataset, indices))\n",
    "    return client_data\n",
    "\n",
    "client_datasets = split_data(train_set)\n",
    "testloader = DataLoader(test_set, batch_size=32, shuffle=False)\n",
    "\n",
    "print(f\"‚úÖ Total images: {len(full_dataset)}\")\n",
    "print(f\"Train: {len(train_set)} | Test: {len(test_set)} | Eval: {len(eval_set)}\")\n",
    "print(f\"Clients: {len(client_datasets)}\")\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# 4. Client Update Function\n",
    "# -------------------------------------------------------------\n",
    "def client_update(model, dataset, epochs, batch_size, lr, testloader=None):\n",
    "    model = copy.deepcopy(model)\n",
    "    model.train()\n",
    "    optimizer = optim.SGD(model.parameters(), lr=lr, momentum=0.9)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    for _ in range(epochs):\n",
    "        for images, labels in loader:\n",
    "            images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "    if testloader:\n",
    "        model.eval()\n",
    "        all_preds, all_labels = [], []\n",
    "        with torch.no_grad():\n",
    "            for images, labels in testloader:\n",
    "                images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
    "                outputs = model(images)\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "                all_preds.extend(preds.cpu().numpy())\n",
    "                all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "        acc = accuracy_score(all_labels, all_preds)\n",
    "        precision = precision_score(all_labels, all_preds, average='macro', zero_division=0)\n",
    "        recall = recall_score(all_labels, all_preds, average='macro', zero_division=0)\n",
    "        f1 = f1_score(all_labels, all_preds, average='macro', zero_division=0)\n",
    "\n",
    "        print(f\"üìç Client Evaluation ‚Üí Acc: {acc:.4f}, Prec: {precision:.4f}, Rec: {recall:.4f}, F1: {f1:.4f}\")\n",
    "\n",
    "    return model.state_dict()\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# ‚úÖ FedYogi Server Optimizer\n",
    "# -------------------------------------------------------------\n",
    "def fed_yogi_update(global_model, client_models, delta_prev, v_prev,\n",
    "                    beta1=0.9, beta2=0.99, eta=0.01, tau=1e-3):\n",
    "    global_state = global_model.state_dict()\n",
    "    delta = {}\n",
    "\n",
    "    for key in global_state.keys():\n",
    "        # Ensure consistent dtype/device\n",
    "        base = global_state[key].to(torch.float32).to(DEVICE)\n",
    "        delta[key] = torch.zeros_like(base)\n",
    "\n",
    "        for client_model in client_models:\n",
    "            delta[key] += client_model[key].to(torch.float32).to(DEVICE) - base\n",
    "\n",
    "        delta[key] /= len(client_models)\n",
    "\n",
    "    for key in delta:\n",
    "        delta_prev[key] = beta1 * delta_prev[key].to(torch.float32).to(DEVICE) + (1 - beta1) * delta[key]\n",
    "\n",
    "    for key in delta:\n",
    "        v_prev[key] = v_prev[key].to(torch.float32).to(DEVICE)\n",
    "        v_prev[key] -= (1 - beta2) * torch.sign(v_prev[key] - delta[key]**2) * delta[key]**2\n",
    "\n",
    "    new_state = {}\n",
    "    for key in global_state.keys():\n",
    "        new_state[key] = global_state[key].to(torch.float32).to(DEVICE) + \\\n",
    "                         eta * delta_prev[key] / (torch.sqrt(v_prev[key]) + tau)\n",
    "\n",
    "    global_model.load_state_dict(new_state)\n",
    "    return global_model, delta_prev, v_prev\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# 6. Evaluation Function\n",
    "# -------------------------------------------------------------\n",
    "def evaluate_model(model, dataloader):\n",
    "    model.eval()\n",
    "    all_preds, all_labels = [], []\n",
    "    with torch.no_grad():\n",
    "        for images, labels in dataloader:\n",
    "            images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
    "            outputs = model(images)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    acc = accuracy_score(all_labels, all_preds)\n",
    "    precision = precision_score(all_labels, all_preds, average='macro', zero_division=0)\n",
    "    recall = recall_score(all_labels, all_preds, average='macro', zero_division=0)\n",
    "    f1 = f1_score(all_labels, all_preds, average='macro', zero_division=0)\n",
    "\n",
    "    print(f\"üîç Evaluation Metrics:\")\n",
    "    print(f\"Accuracy  : {acc:.4f}\")\n",
    "    print(f\"Precision : {precision:.4f}\")\n",
    "    print(f\"Recall    : {recall:.4f}\")\n",
    "    print(f\"F1 Score  : {f1:.4f}\")\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# 7. Federated Training Loop (FedYogi)\n",
    "# -------------------------------------------------------------\n",
    "num_clients = 10\n",
    "clients_per_round = 2\n",
    "rounds = 15\n",
    "epochs = 3\n",
    "batch_size = 32\n",
    "learning_rate = 0.001\n",
    "\n",
    "print(f\"üìå Hyperparameters:\")\n",
    "print(f\"Clients           : {num_clients}\")\n",
    "print(f\"Clients per round : {clients_per_round}\")\n",
    "print(f\"Rounds            : {rounds}\")\n",
    "print(f\"Epochs per client : {epochs}\")\n",
    "print(f\"Batch size        : {batch_size}\")\n",
    "print(f\"Learning rate     : {learning_rate}\")\n",
    "\n",
    "global_model = ResNetModel(num_classes=2, pretrained=True).to(DEVICE)\n",
    "delta_prev = {k: torch.zeros_like(v) for k, v in global_model.state_dict().items()}\n",
    "v_prev = {k: torch.ones_like(v) * 1e-3 for k, v in global_model.state_dict().items()}\n",
    "\n",
    "for t in range(rounds):\n",
    "    selected_clients = random.sample(client_datasets, clients_per_round)\n",
    "    client_models = []\n",
    "\n",
    "    for client_data in selected_clients:\n",
    "        updated_weights = client_update(global_model, client_data, epochs, batch_size, learning_rate)\n",
    "        client_models.append(updated_weights)\n",
    "\n",
    "    global_model, delta_prev, v_prev = fed_yogi_update(global_model, client_models, delta_prev, v_prev)\n",
    "    print(f\"\\n‚úÖ Round {t+1} complete\")\n",
    "    evaluate_model(global_model, testloader)\n"
   ],
   "id": "22c23e05240b0d5f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Total images: 1721\n",
      "Train: 1290 | Test: 344 | Eval: 87\n",
      "Clients: 10\n",
      "üìå Hyperparameters:\n",
      "Clients           : 10\n",
      "Clients per round : 2\n",
      "Rounds            : 15\n",
      "Epochs per client : 3\n",
      "Batch size        : 32\n",
      "Learning rate     : 0.001\n",
      "\n",
      "‚úÖ Round 1 complete\n",
      "üîç Evaluation Metrics:\n",
      "Accuracy  : 0.5116\n",
      "Precision : 0.5061\n",
      "Recall    : 0.5060\n",
      "F1 Score  : 0.5056\n",
      "\n",
      "‚úÖ Round 2 complete\n",
      "üîç Evaluation Metrics:\n",
      "Accuracy  : 0.5087\n",
      "Precision : 0.5029\n",
      "Recall    : 0.5028\n",
      "F1 Score  : 0.5023\n",
      "\n",
      "‚úÖ Round 3 complete\n",
      "üîç Evaluation Metrics:\n",
      "Accuracy  : 0.5058\n",
      "Precision : 0.4987\n",
      "Recall    : 0.4987\n",
      "F1 Score  : 0.4976\n",
      "\n",
      "‚úÖ Round 4 complete\n",
      "üîç Evaluation Metrics:\n",
      "Accuracy  : 0.5087\n",
      "Precision : 0.5005\n",
      "Recall    : 0.5004\n",
      "F1 Score  : 0.4985\n",
      "\n",
      "‚úÖ Round 5 complete\n",
      "üîç Evaluation Metrics:\n",
      "Accuracy  : 0.5087\n",
      "Precision : 0.4979\n",
      "Recall    : 0.4981\n",
      "F1 Score  : 0.4938\n",
      "\n",
      "‚úÖ Round 6 complete\n",
      "üîç Evaluation Metrics:\n",
      "Accuracy  : 0.5116\n",
      "Precision : 0.5008\n",
      "Recall    : 0.5007\n",
      "F1 Score  : 0.4963\n",
      "\n",
      "‚úÖ Round 7 complete\n",
      "üîç Evaluation Metrics:\n",
      "Accuracy  : 0.5145\n",
      "Precision : 0.5032\n",
      "Recall    : 0.5030\n",
      "F1 Score  : 0.4977\n",
      "\n",
      "‚úÖ Round 8 complete\n",
      "üîç Evaluation Metrics:\n",
      "Accuracy  : 0.5174\n",
      "Precision : 0.5061\n",
      "Recall    : 0.5056\n",
      "F1 Score  : 0.5001\n",
      "\n",
      "‚úÖ Round 9 complete\n",
      "üîç Evaluation Metrics:\n",
      "Accuracy  : 0.5203\n",
      "Precision : 0.5086\n",
      "Recall    : 0.5079\n",
      "F1 Score  : 0.5014\n",
      "\n",
      "‚úÖ Round 10 complete\n",
      "üîç Evaluation Metrics:\n",
      "Accuracy  : 0.5233\n",
      "Precision : 0.5099\n",
      "Recall    : 0.5086\n",
      "F1 Score  : 0.4988\n",
      "\n",
      "‚úÖ Round 11 complete\n",
      "üîç Evaluation Metrics:\n",
      "Accuracy  : 0.5494\n",
      "Precision : 0.5394\n",
      "Recall    : 0.5333\n",
      "F1 Score  : 0.5216\n",
      "\n",
      "‚úÖ Round 12 complete\n",
      "üîç Evaluation Metrics:\n",
      "Accuracy  : 0.5552\n",
      "Precision : 0.5463\n",
      "Recall    : 0.5382\n",
      "F1 Score  : 0.5248\n",
      "\n",
      "‚úÖ Round 13 complete\n",
      "üîç Evaluation Metrics:\n",
      "Accuracy  : 0.5465\n",
      "Precision : 0.5351\n",
      "Recall    : 0.5273\n",
      "F1 Score  : 0.5082\n",
      "\n",
      "‚úÖ Round 14 complete\n",
      "üîç Evaluation Metrics:\n",
      "Accuracy  : 0.5465\n",
      "Precision : 0.5347\n",
      "Recall    : 0.5254\n",
      "F1 Score  : 0.5009\n",
      "\n",
      "‚úÖ Round 15 complete\n",
      "üîç Evaluation Metrics:\n",
      "Accuracy  : 0.5465\n",
      "Precision : 0.5347\n",
      "Recall    : 0.5249\n",
      "F1 Score  : 0.4989\n"
     ]
    }
   ],
   "execution_count": 2
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
