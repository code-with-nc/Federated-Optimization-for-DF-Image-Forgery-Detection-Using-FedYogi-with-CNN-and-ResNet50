{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "1. Imports and Setup",
   "id": "462a05fb100c4191"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-04T07:51:10.024100Z",
     "start_time": "2025-11-04T07:51:08.112541Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import random\n",
    "import copy\n",
    "\n"
   ],
   "id": "9b8b2c1c9d9f14d",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "2. CNN Model Definition",
   "id": "f166d9a0e3d09de7"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-04T07:51:10.133974Z",
     "start_time": "2025-11-04T07:51:10.111657Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, kernel_size=3, padding=1),  # input: 3x32x32\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),                         # output: 32x16x16\n",
    "\n",
    "            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2)                          # output: 64x8x8\n",
    "        )\n",
    "\n",
    "        # Flatten output size: 64 * 8 * 8 = 4096\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(64 * 8 * 8, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = x.view(x.size(0), -1)  # flatten before FC\n",
    "        x = self.fc(x)\n",
    "        return x"
   ],
   "id": "cd26a96d7d4e9301",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "3. Load and Split Among Clients",
   "id": "31efa2fe3fca25c8"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "63d66ef2e02c7982"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-04T07:51:11.182609Z",
     "start_time": "2025-11-04T07:51:10.142901Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import shutil\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from torchvision import datasets, transforms\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# âš™ï¸ Parameters\n",
    "# -------------------------------------------------------------------\n",
    "NUM_CLIENTS = 10\n",
    "ALPHA = 0.1            # smaller = more non-IID\n",
    "BATCH_SIZE = 32\n",
    "IMG_SIZE = (128, 128)\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# ðŸ—‚ï¸ Source dataset paths\n",
    "# -------------------------------------------------------------------\n",
    "source_au = r\"C:\\Users\\Admin\\OneDrive\\Desktop\\ResearchTrack\\CASIA_FL_Project\\CASIA 1.0 dataset\\CASIA 1.0 dataset\\Au\\Au\"\n",
    "source_tp = r\"C:\\Users\\Admin\\OneDrive\\Desktop\\ResearchTrack\\CASIA_FL_Project\\CASIA 1.0 dataset\\CASIA 1.0 dataset\\Modified Tp\\Tp\"\n",
    "\n",
    "DATA_ROOT = r\"C:\\Users\\Admin\\OneDrive\\Desktop\\ResearchTrack\\CASIA_FL_Project\\data\"\n",
    "auth_dir = os.path.join(DATA_ROOT, \"Authentic\")\n",
    "tamp_dir = os.path.join(DATA_ROOT, \"Tampered\")\n",
    "os.makedirs(auth_dir, exist_ok=True)\n",
    "os.makedirs(tamp_dir, exist_ok=True)\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# ðŸ—ï¸ Copy files once\n",
    "# -------------------------------------------------------------------\n",
    "if len(os.listdir(auth_dir)) == 0:\n",
    "    print(\"ðŸ“¦ Copying Authentic images...\")\n",
    "    for file in os.listdir(source_au):\n",
    "        src = os.path.join(source_au, file)\n",
    "        dst = os.path.join(auth_dir, file)\n",
    "        if os.path.isfile(src):\n",
    "            shutil.copy(src, dst)\n",
    "\n",
    "if len(os.listdir(tamp_dir)) == 0:\n",
    "    print(\"ðŸ“¦ Copying Tampered images...\")\n",
    "    for file in os.listdir(source_tp):\n",
    "        src = os.path.join(source_tp, file)\n",
    "        dst = os.path.join(tamp_dir, file)\n",
    "        if os.path.isfile(src):\n",
    "            shutil.copy(src, dst)\n",
    "\n",
    "print(\"âœ… Data organized in ImageFolder structure.\\n\")\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# ðŸ§© Transforms\n",
    "# -------------------------------------------------------------------\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize(IMG_SIZE),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# ðŸ“¦ Load dataset\n",
    "# -------------------------------------------------------------------\n",
    "full_dataset = datasets.ImageFolder(DATA_ROOT, transform=transform)\n",
    "print(f\"âœ… Total images: {len(full_dataset)} | Classes: {full_dataset.classes}\")\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# âœ‚ï¸ Class-wise Train/Test Split (80/20)\n",
    "# -------------------------------------------------------------------\n",
    "targets = np.array(full_dataset.targets)\n",
    "indices = np.arange(len(full_dataset))\n",
    "\n",
    "train_indices, test_indices = train_test_split(\n",
    "    indices,\n",
    "    test_size=0.2,\n",
    "    stratify=targets,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "train_dataset = Subset(full_dataset, train_indices)\n",
    "test_dataset = Subset(full_dataset, test_indices)\n",
    "\n",
    "print(f\"Train: {len(train_dataset)} | Test: {len(test_dataset)}\")\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# ðŸ§  Safe Dirichlet non-IID split\n",
    "# -------------------------------------------------------------------\n",
    "def noniid_dirichlet_split(dataset, num_clients, alpha):\n",
    "    \"\"\"\n",
    "    Safe Dirichlet non-IID split. Ensures no client has zero samples.\n",
    "    \"\"\"\n",
    "    targets = np.array([dataset.dataset.targets[i] for i in dataset.indices])\n",
    "    num_classes = len(np.unique(targets))\n",
    "    class_indices = [np.where(targets == y)[0] for y in range(num_classes)]\n",
    "\n",
    "    client_indices = [[] for _ in range(num_clients)]\n",
    "\n",
    "    for c, idx_c in enumerate(class_indices):\n",
    "        np.random.shuffle(idx_c)\n",
    "        proportions = np.random.dirichlet(alpha=np.repeat(alpha, num_clients))\n",
    "        proportions = np.maximum(proportions, 0.001)\n",
    "        proportions = proportions / proportions.sum()\n",
    "        split_points = (np.cumsum(proportions) * len(idx_c)).astype(int)[:-1]\n",
    "        class_split = np.split(idx_c, split_points)\n",
    "\n",
    "        for i in range(num_clients):\n",
    "            if len(class_split[i]) > 0:\n",
    "                client_indices[i].extend(np.array(dataset.indices)[class_split[i]])\n",
    "\n",
    "    client_datasets = [Subset(dataset.dataset, inds) for inds in client_indices if len(inds) > 0]\n",
    "    return client_datasets\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# ðŸ§© Create client datasets and loaders\n",
    "# -------------------------------------------------------------------\n",
    "client_datasets = noniid_dirichlet_split(train_dataset, NUM_CLIENTS, ALPHA)\n",
    "\n",
    "client_loaders = [\n",
    "    DataLoader(cd, batch_size=BATCH_SIZE, shuffle=True)\n",
    "    for cd in client_datasets if len(cd) > 0\n",
    "]\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# ðŸ§¾ Global test DataLoader\n",
    "# -------------------------------------------------------------------\n",
    "testloader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# ðŸ“Š Display summary\n",
    "# -------------------------------------------------------------------\n",
    "print(f\"\\nâœ… Created {len(client_loaders)} clients (target: {NUM_CLIENTS}) | Dirichlet Î±={ALPHA}\")\n",
    "for i, cdata in enumerate(client_datasets[:5]):  # print only first 5 clients for brevity\n",
    "    labels = [full_dataset.targets[idx] for idx in cdata.indices]\n",
    "    unique, counts = np.unique(labels, return_counts=True)\n",
    "    label_map = {full_dataset.classes[u]: int(c) for u, c in zip(unique, counts)}\n",
    "    print(f\"Client {i+1}: {len(cdata)} samples | {label_map}\")\n"
   ],
   "id": "531898cb2a29a321",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Data organized in ImageFolder structure.\n",
      "\n",
      "âœ… Total images: 1721 | Classes: ['Authentic', 'Tampered']\n",
      "Train: 1376 | Test: 345\n",
      "\n",
      "âœ… Created 10 clients (target: 10) | Dirichlet Î±=0.1\n",
      "Client 1: 2 samples | {'Tampered': 2}\n",
      "Client 2: 21 samples | {'Authentic': 5, 'Tampered': 16}\n",
      "Client 3: 501 samples | {'Authentic': 443, 'Tampered': 58}\n",
      "Client 4: 37 samples | {'Authentic': 2, 'Tampered': 35}\n",
      "Client 5: 166 samples | {'Authentic': 155, 'Tampered': 11}\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "4. Client Update Function",
   "id": "698f5659a5d4de84"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-04T07:51:11.204130Z",
     "start_time": "2025-11-04T07:51:11.200471Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def client_update(model, dataset, epochs, batch_size, lr, testloader=None):\n",
    "    model = copy.deepcopy(model)\n",
    "    model.train()\n",
    "    optimizer = optim.SGD(model.parameters(), lr=lr)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    for _ in range(epochs):\n",
    "        for images, labels in loader:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "    # âœ… Optional: Evaluate client model after training\n",
    "    if testloader:\n",
    "        model.eval()\n",
    "        all_preds, all_labels = [], []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for images, labels in testloader:\n",
    "                outputs = model(images)\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "                all_preds.extend(preds.cpu().numpy())\n",
    "                all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "        acc = accuracy_score(all_labels, all_preds)\n",
    "        precision = precision_score(all_labels, all_preds, average='macro', zero_division=0)\n",
    "        recall = recall_score(all_labels, all_preds, average='macro', zero_division=0)\n",
    "        f1 = f1_score(all_labels, all_preds, average='macro', zero_division=0)\n",
    "\n",
    "        print(f\"ðŸ“ Client model evaluation after local training:\")\n",
    "        print(f\"Accuracy  : {acc:.4f}\")\n",
    "        print(f\"Precision : {precision:.4f}\")\n",
    "        print(f\"Recall    : {recall:.4f}\")\n",
    "        print(f\"F1 Score  : {f1:.4f}\")\n",
    "\n",
    "    return model.state_dict()\n"
   ],
   "id": "b00c1677cd1d5cbe",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "5. FedYogi Server Optimizer",
   "id": "610918056e535759"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-04T07:51:11.241779Z",
     "start_time": "2025-11-04T07:51:11.223990Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def fed_yogi_update(global_model, client_models, delta_prev, v_prev, beta1=0.9, beta2=0.99, eta=0.01, tau=1e-3):\n",
    "    # Step 1: Compute average client update (delta)\n",
    "    delta = {}\n",
    "    for key in global_model.state_dict().keys():\n",
    "        delta[key] = torch.zeros_like(global_model.state_dict()[key])\n",
    "        for client_model in client_models:\n",
    "            delta[key] += client_model[key] - global_model.state_dict()[key]\n",
    "        delta[key] /= len(client_models)\n",
    "\n",
    "    # Step 2: Update first moment estimate (momentum)\n",
    "    for key in delta:\n",
    "        delta_prev[key] = beta1 * delta_prev[key] + (1 - beta1) * delta[key]\n",
    "\n",
    "    # Step 3: Update second moment estimate (Yogi-style)\n",
    "    for key in delta:\n",
    "        v_prev[key] -= (1 - beta2) * torch.sign(v_prev[key] - delta[key]**2) * delta[key]**2\n",
    "\n",
    "    # Step 4: Apply adaptive update to global model\n",
    "    new_state = {}\n",
    "    for key in global_model.state_dict().keys():\n",
    "        new_state[key] = global_model.state_dict()[key] + eta * delta_prev[key] / (torch.sqrt(v_prev[key]) + tau)\n",
    "\n",
    "    global_model.load_state_dict(new_state)\n",
    "    return global_model, delta_prev, v_prev\n"
   ],
   "id": "bb5784b69b9cd91c",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "6. Evaluation Function",
   "id": "823d7cb4dea5208f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-04T07:51:11.264050Z",
     "start_time": "2025-11-04T07:51:11.253069Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def evaluate_model(model, dataloader):\n",
    "    model.eval()\n",
    "    all_preds, all_labels = [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in dataloader:\n",
    "            outputs = model(images)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    # âœ… Add these lines here to suppress warnings and handle undefined metrics\n",
    "    acc = accuracy_score(all_labels, all_preds)\n",
    "    precision = precision_score(all_labels, all_preds, average='macro', zero_division=0)\n",
    "    recall = recall_score(all_labels, all_preds, average='macro', zero_division=0)\n",
    "    f1 = f1_score(all_labels, all_preds, average='macro', zero_division=0)\n",
    "\n",
    "    print(f\"ðŸ” Evaluation Metrics:\")\n",
    "    print(f\"Accuracy  : {acc:.4f}\")\n",
    "    print(f\"Precision : {precision:.4f}\")\n",
    "    print(f\"Recall    : {recall:.4f}\")\n",
    "    print(f\"F1 Score  : {f1:.4f}\")\n",
    "\n"
   ],
   "id": "e0c9841559b241c0",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "7. Federated Training Loop with Logging",
   "id": "c51bf42ebbdb205c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-04T07:51:11.658837Z",
     "start_time": "2025-11-04T07:51:11.273770Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Hyperparameters\n",
    "num_clients = 10\n",
    "clients_per_round = 2\n",
    "rounds = 100\n",
    "epochs = 2\n",
    "batch_size = 32\n",
    "learning_rate = 0.001\n",
    "\n",
    "print(f\"ðŸ“Œ Hyperparameters:\")\n",
    "print(f\"Clients           : {num_clients}\")\n",
    "print(f\"Clients per round : {clients_per_round}\")\n",
    "print(f\"Rounds            : {rounds}\")\n",
    "print(f\"Epochs per client : {epochs}\")\n",
    "print(f\"Batch size        : {batch_size}\")\n",
    "print(f\"Learning rate     : {learning_rate}\")\n",
    "\n",
    "\n",
    "\n",
    "global_model = SimpleCNN()\n",
    "delta_prev = {k: torch.zeros_like(v) for k, v in global_model.state_dict().items()}\n",
    "v_prev = {k: torch.ones_like(v) * 1e-3 for k, v in global_model.state_dict().items()}\n",
    "\n",
    "for t in range(rounds):\n",
    "    selected_clients = random.sample(client_datasets, clients_per_round)\n",
    "    client_models = []\n",
    "\n",
    "    for client_data in selected_clients:\n",
    "        updated_weights = client_update(global_model, client_data, epochs, batch_size, learning_rate)\n",
    "        client_models.append(updated_weights)\n",
    "\n",
    "    global_model, delta_prev, v_prev = fed_yogi_update(global_model, client_models, delta_prev, v_prev)\n",
    "    print(f\"\\nâœ… Round {t+1} complete\")\n",
    "    evaluate_model(global_model, testloader)\n"
   ],
   "id": "ba79cd3a602eac79",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“Œ Hyperparameters:\n",
      "Clients           : 10\n",
      "Clients per round : 2\n",
      "Rounds            : 100\n",
      "Epochs per client : 2\n",
      "Batch size        : 32\n",
      "Learning rate     : 0.001\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (2x65536 and 4096x128)",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mRuntimeError\u001B[39m                              Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[7]\u001B[39m\u001B[32m, line 28\u001B[39m\n\u001B[32m     25\u001B[39m client_models = []\n\u001B[32m     27\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m client_data \u001B[38;5;129;01min\u001B[39;00m selected_clients:\n\u001B[32m---> \u001B[39m\u001B[32m28\u001B[39m     updated_weights = \u001B[43mclient_update\u001B[49m\u001B[43m(\u001B[49m\u001B[43mglobal_model\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mclient_data\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mepochs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlearning_rate\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     29\u001B[39m     client_models.append(updated_weights)\n\u001B[32m     31\u001B[39m global_model, delta_prev, v_prev = fed_yogi_update(global_model, client_models, delta_prev, v_prev)\n",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[4]\u001B[39m\u001B[32m, line 11\u001B[39m, in \u001B[36mclient_update\u001B[39m\u001B[34m(model, dataset, epochs, batch_size, lr, testloader)\u001B[39m\n\u001B[32m      9\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m images, labels \u001B[38;5;129;01min\u001B[39;00m loader:\n\u001B[32m     10\u001B[39m     optimizer.zero_grad()\n\u001B[32m---> \u001B[39m\u001B[32m11\u001B[39m     outputs = \u001B[43mmodel\u001B[49m\u001B[43m(\u001B[49m\u001B[43mimages\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     12\u001B[39m     loss = criterion(outputs, labels)\n\u001B[32m     13\u001B[39m     loss.backward()\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\torch\\nn\\modules\\module.py:1751\u001B[39m, in \u001B[36mModule._wrapped_call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1749\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m._compiled_call_impl(*args, **kwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[32m   1750\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m-> \u001B[39m\u001B[32m1751\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\torch\\nn\\modules\\module.py:1762\u001B[39m, in \u001B[36mModule._call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1757\u001B[39m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[32m   1758\u001B[39m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[32m   1759\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m._backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_pre_hooks\n\u001B[32m   1760\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[32m   1761\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[32m-> \u001B[39m\u001B[32m1762\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1764\u001B[39m result = \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m   1765\u001B[39m called_always_called_hooks = \u001B[38;5;28mset\u001B[39m()\n",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[2]\u001B[39m\u001B[32m, line 25\u001B[39m, in \u001B[36mSimpleCNN.forward\u001B[39m\u001B[34m(self, x)\u001B[39m\n\u001B[32m     23\u001B[39m x = \u001B[38;5;28mself\u001B[39m.conv(x)\n\u001B[32m     24\u001B[39m x = x.view(x.size(\u001B[32m0\u001B[39m), -\u001B[32m1\u001B[39m)  \u001B[38;5;66;03m# flatten before FC\u001B[39;00m\n\u001B[32m---> \u001B[39m\u001B[32m25\u001B[39m x = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mfc\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     26\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m x\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\torch\\nn\\modules\\module.py:1751\u001B[39m, in \u001B[36mModule._wrapped_call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1749\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m._compiled_call_impl(*args, **kwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[32m   1750\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m-> \u001B[39m\u001B[32m1751\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\torch\\nn\\modules\\module.py:1762\u001B[39m, in \u001B[36mModule._call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1757\u001B[39m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[32m   1758\u001B[39m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[32m   1759\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m._backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_pre_hooks\n\u001B[32m   1760\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[32m   1761\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[32m-> \u001B[39m\u001B[32m1762\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1764\u001B[39m result = \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m   1765\u001B[39m called_always_called_hooks = \u001B[38;5;28mset\u001B[39m()\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\torch\\nn\\modules\\container.py:240\u001B[39m, in \u001B[36mSequential.forward\u001B[39m\u001B[34m(self, input)\u001B[39m\n\u001B[32m    238\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m):\n\u001B[32m    239\u001B[39m     \u001B[38;5;28;01mfor\u001B[39;00m module \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m:\n\u001B[32m--> \u001B[39m\u001B[32m240\u001B[39m         \u001B[38;5;28minput\u001B[39m = \u001B[43mmodule\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[32m    241\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28minput\u001B[39m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\torch\\nn\\modules\\module.py:1751\u001B[39m, in \u001B[36mModule._wrapped_call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1749\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m._compiled_call_impl(*args, **kwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[32m   1750\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m-> \u001B[39m\u001B[32m1751\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\torch\\nn\\modules\\module.py:1762\u001B[39m, in \u001B[36mModule._call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1757\u001B[39m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[32m   1758\u001B[39m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[32m   1759\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m._backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_pre_hooks\n\u001B[32m   1760\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[32m   1761\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[32m-> \u001B[39m\u001B[32m1762\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1764\u001B[39m result = \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m   1765\u001B[39m called_always_called_hooks = \u001B[38;5;28mset\u001B[39m()\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\torch\\nn\\modules\\linear.py:125\u001B[39m, in \u001B[36mLinear.forward\u001B[39m\u001B[34m(self, input)\u001B[39m\n\u001B[32m    124\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m: Tensor) -> Tensor:\n\u001B[32m--> \u001B[39m\u001B[32m125\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mF\u001B[49m\u001B[43m.\u001B[49m\u001B[43mlinear\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mweight\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mbias\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[31mRuntimeError\u001B[39m: mat1 and mat2 shapes cannot be multiplied (2x65536 and 4096x128)"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# === Step 1: Load your Excel file ===\n",
    "file_path = r\"C:\\Users\\Admin\\OneDrive\\Desktop\\ResearchTrack\\CASIA_FL_Project\\models\\data\\fedyogi_raw_noniid.xlsx\"\n",
    "  # <-- change to your file name\n",
    "\n",
    "# Read all cells as text (to handle mixed formatting)\n",
    "df = pd.read_excel(file_path, header=None)\n",
    "\n",
    "# Combine all cells into one text block (since your Excel might have 1 column or merged cells)\n",
    "text = \" \".join(df.astype(str).fillna(\"\").values.flatten())\n",
    "\n",
    "# === Step 2: Extract Hyperparameters ===\n",
    "hyper_pattern = re.compile(\n",
    "    r\"Clients\\s*:\\s*(\\d+).*?\"\n",
    "    r\"Clients per round\\s*:\\s*(\\d+).*?\"\n",
    "    r\"Rounds\\s*:\\s*(\\d+).*?\"\n",
    "    r\"Epochs per client\\s*:\\s*(\\d+).*?\"\n",
    "    r\"Batch size\\s*:\\s*(\\d+).*?\"\n",
    "    r\"Learning rate\\s*:\\s*([\\d.]+)\",\n",
    "    re.DOTALL\n",
    ")\n",
    "\n",
    "hyper = hyper_pattern.search(text)\n",
    "if hyper:\n",
    "    clients, cpr, rounds, epochs, batch, lr = hyper.groups()\n",
    "    base_info = {\n",
    "        \"Clients\": int(clients),\n",
    "        \"Clients per round\": int(cpr),\n",
    "        \"Total Rounds\": int(rounds),\n",
    "        \"Epochs per client\": int(epochs),\n",
    "        \"Batch size\": int(batch),\n",
    "        \"Learning rate\": float(lr)\n",
    "    }\n",
    "else:\n",
    "    base_info = {}\n",
    "\n",
    "# === Step 3: Extract metrics per round ===\n",
    "pattern = re.compile(\n",
    "    r\"Round\\s*(\\d+).*?\"\n",
    "    r\"Accuracy\\s*:\\s*([\\d.]+).*?\"\n",
    "    r\"Precision\\s*:\\s*([\\d.]+).*?\"\n",
    "    r\"Recall\\s*:\\s*([\\d.]+).*?\"\n",
    "    r\"F1\\s*Score\\s*:\\s*([\\d.]+)\",\n",
    "    re.DOTALL\n",
    ")\n",
    "\n",
    "matches = pattern.findall(text)\n",
    "\n",
    "data = []\n",
    "for m in matches:\n",
    "    round_num, acc, prec, rec, f1 = m\n",
    "    data.append({\n",
    "        \"Round\": int(round_num),\n",
    "        \"Accuracy\": float(acc),\n",
    "        \"Precision\": float(prec),\n",
    "        \"Recall\": float(rec),\n",
    "        \"F1 Score\": float(f1)\n",
    "    })\n",
    "\n",
    "# === Step 4: Create structured DataFrame ===\n",
    "processed = pd.DataFrame(data)\n",
    "\n",
    "for k, v in base_info.items():\n",
    "    processed[k] = v\n",
    "\n",
    "cols = [\n",
    "    \"Round\", \"Accuracy\", \"Precision\", \"Recall\", \"F1 Score\",\n",
    "    \"Clients\", \"Clients per round\", \"Total Rounds\",\n",
    "    \"Epochs per client\", \"Batch size\", \"Learning rate\"\n",
    "]\n",
    "processed = processed[cols]\n",
    "\n",
    "# === Step 5: Save processed output ===\n",
    "output_path = \"processed_fedyogi_results_noniid.xlsx\"\n",
    "processed.to_excel(output_path, index=False)\n",
    "\n",
    "print(f\"âœ… Processed {len(processed)} rounds successfully!\")\n",
    "print(f\"ðŸ“Š File saved as: {output_path}\")\n"
   ],
   "id": "d98fc4004678b62c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# === Step 1: Load processed Excel file ===\n",
    "file_path = r\"C:\\Users\\Admin\\OneDrive\\Desktop\\ResearchTrack\\CASIA_FL_Project\\models\\processed_fedyogi_results_noniid.xlsx\"  # change if needed\n",
    "df = pd.read_excel(file_path)\n",
    "\n",
    "# === Step 2: Check available columns ===\n",
    "print(\"âœ… Columns found:\", df.columns.tolist())\n",
    "\n",
    "# === Step 3: Create plots ===\n",
    "metrics = [\"Accuracy\", \"Precision\", \"Recall\", \"F1 Score\"]\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "for i, metric in enumerate(metrics, 1):\n",
    "    plt.subplot(2, 2, i)  # 2 rows, 2 columns, subplot index\n",
    "    plt.plot(df[\"Round\"], df[metric], label=metric, linewidth=1.5)\n",
    "    plt.xlabel(\"Round\")\n",
    "    plt.ylabel(metric)\n",
    "    plt.title(f\"{metric} vs Rounds\")\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.suptitle(\"Federated Learning Performance Metrics per Round\", fontsize=14, y=1.02)\n",
    "plt.savefig(\"fedyogi_performance_plots.png\", dpi=300, bbox_inches=\"tight\")\n",
    "plt.show()\n"
   ],
   "id": "fa630de2a4f06b1d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# === Step 1: File paths ===\n",
    "file_noniid = r\"C:\\Users\\Admin\\OneDrive\\Desktop\\ResearchTrack\\CASIA_FL_Project\\models\\processed_fedyogi_results_noniid.xlsx\"\n",
    "file_iid = r\"C:\\Users\\Admin\\OneDrive\\Desktop\\ResearchTrack\\Federated Learning\\FedYogi\\processed_fedyogi_results.xlsx\"\n",
    "\n",
    "# === Step 2: Read both files ===\n",
    "df_noniid = pd.read_excel(file_noniid)\n",
    "df_iid = pd.read_excel(file_iid)\n",
    "\n",
    "# === Step 3: Basic check ===\n",
    "print(\"Non-IID columns:\", df_noniid.columns.tolist())\n",
    "print(\"IID columns:\", df_iid.columns.tolist())\n",
    "\n",
    "# === Step 4: Align both by 'Round' column ===\n",
    "max_round = min(df_noniid[\"Round\"].max(), df_iid[\"Round\"].max())\n",
    "df_noniid = df_noniid[df_noniid[\"Round\"] <= max_round]\n",
    "df_iid = df_iid[df_iid[\"Round\"] <= max_round]\n",
    "\n",
    "# === Step 5: Define metrics to compare ===\n",
    "metrics = [\"Accuracy\", \"Precision\", \"Recall\", \"F1 Score\"]\n",
    "\n",
    "# === Step 6: Set up white background and plot style ===\n",
    "plt.style.use(\"default\")\n",
    "plt.rcParams[\"axes.facecolor\"] = \"white\"\n",
    "plt.rcParams[\"figure.facecolor\"] = \"white\"\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "# === Step 7: Create comparison plots ===\n",
    "for i, metric in enumerate(metrics, 1):\n",
    "    plt.subplot(2, 2, i)\n",
    "    plt.plot(df_iid[\"Round\"], df_iid[metric], color=\"#007BFF\", label=\"IID Dataset\", linewidth=2)        # bright blue\n",
    "    plt.plot(df_noniid[\"Round\"], df_noniid[metric], color=\"#FF6600\", label=\"Non-IID Dataset\", linewidth=2)  # orange dashed\n",
    "    plt.xlabel(\"Round\", fontsize=10)\n",
    "    plt.ylabel(metric, fontsize=10)\n",
    "    plt.title(f\"{metric} vs Rounds\", fontsize=11, fontweight=\"bold\")\n",
    "    plt.grid(True, linestyle=\":\", alpha=0.7)\n",
    "    plt.legend(fontsize=9)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.suptitle(\"FedYogi: IID vs Non-IID Performance Comparison\", fontsize=14, fontweight=\"bold\", y=1.03)\n",
    "\n",
    "# === Step 8: Save before showing ===\n",
    "plt.savefig(\"fedyogi_iid_vs_noniid_comparison.png\", dpi=300, bbox_inches=\"tight\")\n",
    "\n",
    "# === Step 9: Display ===\n",
    "plt.show()\n"
   ],
   "id": "6a32802b0e4713ca",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
